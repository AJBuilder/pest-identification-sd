{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8aa721-cf73-4e8c-b206-797336fb2a6d",
   "metadata": {},
   "source": [
    "# Training a Model\n",
    "***\n",
    "This notebook is for training a model with default hyperparameters and the mobilenet-v2-100-224 model.\n",
    "\n",
    "To Do:\n",
    "- Adding explicit verification and testing channels\n",
    "- Making sure hypder parameters are what we want.\n",
    "- Ensuring output log file is saved to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "477b49c6-1e8c-4802-9616-b9ad8edf8953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::447099698275:role/service-role/AmazonSageMaker-ExecutionRole-20230114T111418\n",
      "using bucket sagemaker-us-east-2-447099698275\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "\n",
    "print(\"using bucket %s\" % bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f4710af-9887-4280-9c0a-25aad3a6cc31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-script-bucket-mirror/transfer-learning/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "\n",
    "# Here, we are retrieving the URIs to all the default Docker images, training scripts, and pretrained models\n",
    "# that are provided by Jumpstart\n",
    "# Note we are just retrieving links to these things. They will be assembled later in the Estimator, Model, or Predictor\n",
    "# Estimators are for training.\n",
    "# Models are for deployment.\n",
    "# Predictors are for inference.\n",
    "\n",
    "model_id, model_version = \"tensorflow-ic-imagenet-mobilenet-v2-100-224-classification-4\", \"*\"\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "# Retrieve the training script\n",
    "#train_source_uri = script_uris.retrieve(\n",
    " #   model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    "#)\n",
    "\n",
    "train_source_uri = \"s3://sagemaker-script-bucket-mirror/transfer-learning/sourcedir.tar.gz\"\n",
    "\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    ")\n",
    "\n",
    "print(train_source_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0093804c-b92a-46af-99f6-4425f37add46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-447099698275/slf-classifier-training/output\n"
     ]
    }
   ],
   "source": [
    "# Our training data\n",
    "training_data_bucket = f\"lantern-rd-pictures\"\n",
    "training_dataset_s3_path = f\"s3://{training_data_bucket}/\"\n",
    "\n",
    "#Our test data\n",
    "test_data_bucket = f\"lantern-rd-test-pictures\"\n",
    "test_dataset_s3_path = f\"s3://{test_data_bucket}/\"\n",
    "\n",
    "# Output\n",
    "output_bucket = bucket\n",
    "output_prefix = \"slf-classifier-training\"\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\"\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "163ab627-073f-47e5-aee4-c07cfd751fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_only_top_layer': 'True', 'epochs': '18', 'batch_size': '32', 'optimizer': 'adam', 'learning_rate': '0.001', 'beta_1': '0.9', 'beta_2': '0.999', 'momentum': '0.9', 'epsilon': '0.0000001', 'rho': '0.95', 'initial_accumulator_value': '0.1', 'reinitialize_top_layer': 'True', 'early_stopping': 'False', 'early_stopping_patience': '5', 'early_stopping_min_delta': '0.0', 'dropout_rate': '0.2', 'regularizers_l2': '0.0001', 'label_smoothing': '0.1', 'image_resize_interpolation': 'bilinear', 'augmentation': 'True', 'augmentation_random_flip': 'horizontal_and_vertical', 'augmentation_random_rotation': '0.5', 'augmentation_random_zoom': '0.1', 'binary_mode': 'False', 'eval_metric': 'accuracy', 'validation_split_ratio': '0.2', 'random_seed': '123'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "#hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters = {\n",
    "    \"train_only_top_layer\" : \"True\",\n",
    "    \"epochs\" : \"18\",\n",
    "    \"batch_size\" : \"32\",\n",
    "    \"optimizer\" : \"adam\",\n",
    "    \"learning_rate\" : \"0.001\",\n",
    "    \"beta_1\" : \"0.9\",\n",
    "    \"beta_2\" : \"0.999\",\n",
    "    \"momentum\" : \"0.9\",\n",
    "    \"epsilon\" : \"0.0000001\",\n",
    "    \"rho\" : \"0.95\",\n",
    "    \"initial_accumulator_value\" : \"0.1\",\n",
    "    \"reinitialize_top_layer\" : \"True\",\n",
    "    \"early_stopping\" : \"False\",\n",
    "    \"early_stopping_patience\" : \"5\",\n",
    "    \"early_stopping_min_delta\" : \"0.0\",\n",
    "    \"dropout_rate\" : \"0.2\",\n",
    "    \"regularizers_l2\" : \"0.0001\",\n",
    "    \"label_smoothing\" : \"0.1\",\n",
    "    \"image_resize_interpolation\" : \"bilinear\",\n",
    "    \"augmentation\" : \"True\",\n",
    "    \"augmentation_random_flip\" : \"horizontal_and_vertical\",\n",
    "    \"augmentation_random_rotation\" : \"0.5\",\n",
    "    \"augmentation_random_zoom\" : \"0.1\",\n",
    "    \"binary_mode\" : \"False\",\n",
    "    \"eval_metric\" : \"accuracy\",\n",
    "    \"validation_split_ratio\" : \"0.2\",\n",
    "    \"random_seed\" : \"123\"\n",
    "}\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a12bd457-fbdb-450a-b28b-b02c611a14c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter\n",
    "\n",
    "#######################################################\n",
    "# Use AMT for tuning and selecting the best model\n",
    "# Setting to false will use Automatic Model Tuning\n",
    "# Will use hp_tuner instead of ic_estimator\n",
    "use_amt = False\n",
    "######################################################\n",
    "\n",
    "# Define objective metric per framework, based on which the best model will be selected.\n",
    "metric_definitions_per_model = {\n",
    "    \"tensorflow\": {\n",
    "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Maximize\",\n",
    "    },\n",
    "    \"pytorch\": {\n",
    "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val Acc: ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Maximize\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
    "hyperparameter_ranges = {\n",
    "    \"adam-learning-rate\": ContinuousParameter(0.0001, 0.1, scaling_type=\"Logarithmic\")\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 6\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c09ec9c-dda5-4fae-a6b6-43df9c9de773",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-09 16:08:40 Starting - Starting the training job...\n",
      "2023-02-09 16:09:03 Starting - Preparing the instances for trainingProfilerReport-1675958919: InProgress\n",
      "......\n",
      "2023-02-09 16:10:03 Downloading - Downloading input data...\n",
      "2023-02-09 16:10:41 Training - Downloading the training image......\n",
      "2023-02-09 16:11:23 Training - Training image download completed. Training in progress.\u001b[34m2023-02-09 16:11:22.134941: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:22.135102: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:22.160609: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24,086 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24,096 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24,312 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24,329 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24,346 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24,355 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"augmentation\": \"True\",\n",
      "        \"augmentation_random_flip\": \"horizontal_and_vertical\",\n",
      "        \"augmentation_random_rotation\": \"0.5\",\n",
      "        \"augmentation_random_zoom\": \"0.1\",\n",
      "        \"batch_size\": \"32\",\n",
      "        \"beta_1\": \"0.9\",\n",
      "        \"beta_2\": \"0.999\",\n",
      "        \"binary_mode\": \"False\",\n",
      "        \"dropout_rate\": \"0.2\",\n",
      "        \"early_stopping\": \"False\",\n",
      "        \"early_stopping_min_delta\": \"0.0\",\n",
      "        \"early_stopping_patience\": \"5\",\n",
      "        \"epochs\": \"18\",\n",
      "        \"epsilon\": \"0.0000001\",\n",
      "        \"eval_metric\": \"accuracy\",\n",
      "        \"image_resize_interpolation\": \"bilinear\",\n",
      "        \"initial_accumulator_value\": \"0.1\",\n",
      "        \"label_smoothing\": \"0.1\",\n",
      "        \"learning_rate\": \"0.001\",\n",
      "        \"momentum\": \"0.9\",\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"random_seed\": \"123\",\n",
      "        \"regularizers_l2\": \"0.0001\",\n",
      "        \"reinitialize_top_layer\": \"True\",\n",
      "        \"rho\": \"0.95\",\n",
      "        \"train_only_top_layer\": \"True\",\n",
      "        \"validation_split_ratio\": \"0.2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"slf-tensorflow-ic-imagenet-mobilenet-v2-2023-02-09-16-08-39-980\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-script-bucket-mirror/transfer-learning/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"augmentation\":\"True\",\"augmentation_random_flip\":\"horizontal_and_vertical\",\"augmentation_random_rotation\":\"0.5\",\"augmentation_random_zoom\":\"0.1\",\"batch_size\":\"32\",\"beta_1\":\"0.9\",\"beta_2\":\"0.999\",\"binary_mode\":\"False\",\"dropout_rate\":\"0.2\",\"early_stopping\":\"False\",\"early_stopping_min_delta\":\"0.0\",\"early_stopping_patience\":\"5\",\"epochs\":\"18\",\"epsilon\":\"0.0000001\",\"eval_metric\":\"accuracy\",\"image_resize_interpolation\":\"bilinear\",\"initial_accumulator_value\":\"0.1\",\"label_smoothing\":\"0.1\",\"learning_rate\":\"0.001\",\"momentum\":\"0.9\",\"optimizer\":\"adam\",\"random_seed\":\"123\",\"regularizers_l2\":\"0.0001\",\"reinitialize_top_layer\":\"True\",\"rho\":\"0.95\",\"train_only_top_layer\":\"True\",\"validation_split_ratio\":\"0.2\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"test\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-script-bucket-mirror/transfer-learning/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"test\":\"/opt/ml/input/data/test\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"augmentation\":\"True\",\"augmentation_random_flip\":\"horizontal_and_vertical\",\"augmentation_random_rotation\":\"0.5\",\"augmentation_random_zoom\":\"0.1\",\"batch_size\":\"32\",\"beta_1\":\"0.9\",\"beta_2\":\"0.999\",\"binary_mode\":\"False\",\"dropout_rate\":\"0.2\",\"early_stopping\":\"False\",\"early_stopping_min_delta\":\"0.0\",\"early_stopping_patience\":\"5\",\"epochs\":\"18\",\"epsilon\":\"0.0000001\",\"eval_metric\":\"accuracy\",\"image_resize_interpolation\":\"bilinear\",\"initial_accumulator_value\":\"0.1\",\"label_smoothing\":\"0.1\",\"learning_rate\":\"0.001\",\"momentum\":\"0.9\",\"optimizer\":\"adam\",\"random_seed\":\"123\",\"regularizers_l2\":\"0.0001\",\"reinitialize_top_layer\":\"True\",\"rho\":\"0.95\",\"train_only_top_layer\":\"True\",\"validation_split_ratio\":\"0.2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"slf-tensorflow-ic-imagenet-mobilenet-v2-2023-02-09-16-08-39-980\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-script-bucket-mirror/transfer-learning/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--augmentation\",\"True\",\"--augmentation_random_flip\",\"horizontal_and_vertical\",\"--augmentation_random_rotation\",\"0.5\",\"--augmentation_random_zoom\",\"0.1\",\"--batch_size\",\"32\",\"--beta_1\",\"0.9\",\"--beta_2\",\"0.999\",\"--binary_mode\",\"False\",\"--dropout_rate\",\"0.2\",\"--early_stopping\",\"False\",\"--early_stopping_min_delta\",\"0.0\",\"--early_stopping_patience\",\"5\",\"--epochs\",\"18\",\"--epsilon\",\"0.0000001\",\"--eval_metric\",\"accuracy\",\"--image_resize_interpolation\",\"bilinear\",\"--initial_accumulator_value\",\"0.1\",\"--label_smoothing\",\"0.1\",\"--learning_rate\",\"0.001\",\"--momentum\",\"0.9\",\"--optimizer\",\"adam\",\"--random_seed\",\"123\",\"--regularizers_l2\",\"0.0001\",\"--reinitialize_top_layer\",\"True\",\"--rho\",\"0.95\",\"--train_only_top_layer\",\"True\",\"--validation_split_ratio\",\"0.2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENTATION=True\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENTATION_RANDOM_FLIP=horizontal_and_vertical\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENTATION_RANDOM_ROTATION=0.5\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENTATION_RANDOM_ZOOM=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_BETA_1=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_BETA_2=0.999\u001b[0m\n",
      "\u001b[34mSM_HP_BINARY_MODE=False\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING=False\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_MIN_DELTA=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_PATIENCE=5\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=18\u001b[0m\n",
      "\u001b[34mSM_HP_EPSILON=0.0000001\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_METRIC=accuracy\u001b[0m\n",
      "\u001b[34mSM_HP_IMAGE_RESIZE_INTERPOLATION=bilinear\u001b[0m\n",
      "\u001b[34mSM_HP_INITIAL_ACCUMULATOR_VALUE=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_LABEL_SMOOTHING=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=adam\u001b[0m\n",
      "\u001b[34mSM_HP_RANDOM_SEED=123\u001b[0m\n",
      "\u001b[34mSM_HP_REGULARIZERS_L2=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_REINITIALIZE_TOP_LAYER=True\u001b[0m\n",
      "\u001b[34mSM_HP_RHO=0.95\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_ONLY_TOP_LAYER=True\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_SPLIT_RATIO=0.2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages:/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument-3.4.2-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument_cext-0.2.4-py3.9-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.9 transfer_learning.py --augmentation True --augmentation_random_flip horizontal_and_vertical --augmentation_random_rotation 0.5 --augmentation_random_zoom 0.1 --batch_size 32 --beta_1 0.9 --beta_2 0.999 --binary_mode False --dropout_rate 0.2 --early_stopping False --early_stopping_min_delta 0.0 --early_stopping_patience 5 --epochs 18 --epsilon 0.0000001 --eval_metric accuracy --image_resize_interpolation bilinear --initial_accumulator_value 0.1 --label_smoothing 0.1 --learning_rate 0.001 --momentum 0.9 --optimizer adam --random_seed 123 --regularizers_l2 0.0001 --reinitialize_top_layer True --rho 0.95 --train_only_top_layer True --validation_split_ratio 0.2\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24.800948: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24.801109: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2023-02-09 16:11:24.826419: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mRunning training scripts with arguments: Namespace(model_dir=PosixPath('/opt/ml/model'), train='/opt/ml/input/data/training', validation=None, test='/opt/ml/input/data/test', pretrained_model='/opt/ml/input/data/model', hosts=['algo-1'], current_host='algo-1', verbose_one_line_per_epoch=2, checkpoint_save_best_only='True', seed=0, reinitialize_top_layer='True', train_only_top_layer='True', validation_split_ratio=0.2, early_stopping='False', early_stopping_patience=5, early_stopping_min_delta=0.0, dropout_rate=0.2, regularizers_l2=0.0001, label_smoothing=0.1, image_resize_interpolation='bilinear', augmentation='True', augmentation_random_flip='horizontal_and_vertical', augmentation_random_rotation=0.5, augmentation_random_zoom=0.1, epochs=18, batch_size=32, optimizer='adam', learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, momentum=0.9, rho=0.95, initial_accumulator_value=0.1, binary_mode='False', eval_metric='accuracy', random_seed=123)\u001b[0m\n",
      "\u001b[34mIgnoring unrecognized arguments: ['--validation_split_ratio', '0.2']\u001b[0m\n",
      "\u001b[34mimage size for this model is: [224, 224]\u001b[0m\n",
      "\u001b[34mCreating datasets using categorical mode for label encodings.\u001b[0m\n",
      "\u001b[34mImages for this model will be resized to image size: [224, 224]\u001b[0m\n",
      "\u001b[34mFound 2959 files belonging to 2 classes.\u001b[0m\n",
      "\u001b[34mLoading test data from the Test channel.\u001b[0m\n",
      "\u001b[34mFound 80 files belonging to 2 classes.\u001b[0m\n",
      "\u001b[34mClass index to class name mapping: {0: 'not-slf', 1: 'slf-positive'}\u001b[0m\n",
      "\u001b[34mCardinality of train dataset: 2368\u001b[0m\n",
      "\u001b[34mNumber of class examples in train dataset: {'not-slf': 2081, 'slf-positive': 287}\u001b[0m\n",
      "\u001b[34mCardinality of validation dataset: 591\u001b[0m\n",
      "\u001b[34mNumber of class examples in validation dataset: {'not-slf': 532, 'slf-positive': 59}\u001b[0m\n",
      "\u001b[34mCardinality of test dataset: 80\u001b[0m\n",
      "\u001b[34mNumber of class examples in test dataset: {'not-slf': 40, 'slf-positive': 40}\u001b[0m\n",
      "\u001b[34mLoading the original pre-trained feature extraction model, and attaching a randomly initialized classification layer to classify input images to one of the 2 classes.\u001b[0m\n",
      "\u001b[34mSetting model to train only top layer.\u001b[0m\n",
      "\u001b[34mModel: \"model\"\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #\u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34minput_1 (InputLayer)        [(None, 224, 224, 3)]     0\u001b[0m\n",
      "\u001b[34mfeatures (KerasLayer)       (None, 1280)              2257984\u001b[0m\n",
      "\u001b[34mdropout (Dropout)           (None, 1280)              0\u001b[0m\n",
      "\u001b[34mclassification (Dense)      (None, 2)                 2562      \n",
      "                                                                 \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 2,260,546\u001b[0m\n",
      "\u001b[34mTrainable params: 2,562\u001b[0m\n",
      "\u001b[34mNon-trainable params: 2,257,984\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mSince there are 2 <= 5 labels, the metric top_5_accuracy will not be computed.\u001b[0m\n",
      "\u001b[34mSetting the evaluation metric to val_accuracy\u001b[0m\n",
      "\u001b[34mModel information:\u001b[0m\n",
      "\u001b[34m- Number of trainable parameters: 2562\u001b[0m\n",
      "\u001b[34m- Number of non-trainable parameters: 2257984\u001b[0m\n",
      "\u001b[34m- Number of parameters: 2260546\u001b[0m\n",
      "\u001b[34mEpoch 1/18\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34m[2023-02-09 16:11:35.667 ip-10-0-102-177.us-east-2.compute.internal:29 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2023-02-09 16:11:35.899 ip-10-0-102-177.us-east-2.compute.internal:29 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-02-09 16:11:35.919 ip-10-0-102-177.us-east-2.compute.internal:29 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-02-09 16:11:35.919 ip-10-0-102-177.us-east-2.compute.internal:29 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-02-09 16:11:35.920 ip-10-0-102-177.us-east-2.compute.internal:29 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-02-09 16:11:35.920 ip-10-0-102-177.us-east-2.compute.internal:29 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-02-09 16:11:35.921 ip-10-0-102-177.us-east-2.compute.internal:29 INFO hook.py:427] Monitoring the collections: metrics, sm_metrics, losses\u001b[0m\n",
      "\u001b[34m74/74 - 58s - loss: 0.4176 - accuracy: 0.8889 - val_loss: 0.2766 - val_accuracy: 0.9645 - 58s/epoch - 785ms/step\u001b[0m\n",
      "\u001b[34mEpoch 2/18\u001b[0m\n",
      "\u001b[34m74/74 - 54s - loss: 0.3080 - accuracy: 0.9468 - val_loss: 0.2674 - val_accuracy: 0.9712 - 54s/epoch - 733ms/step\u001b[0m\n",
      "\u001b[34mEpoch 3/18\u001b[0m\n",
      "\u001b[34m74/74 - 58s - loss: 0.2895 - accuracy: 0.9595 - val_loss: 0.2482 - val_accuracy: 0.9831 - 58s/epoch - 781ms/step\u001b[0m\n",
      "\u001b[34mEpoch 4/18\u001b[0m\n",
      "\u001b[34m74/74 - 53s - loss: 0.2835 - accuracy: 0.9675 - val_loss: 0.2437 - val_accuracy: 0.9898 - 53s/epoch - 720ms/step\u001b[0m\n",
      "\u001b[34mEpoch 5/18\u001b[0m\n",
      "\u001b[34m74/74 - 54s - loss: 0.2724 - accuracy: 0.9709 - val_loss: 0.2489 - val_accuracy: 0.9831 - 54s/epoch - 731ms/step\u001b[0m\n",
      "\u001b[34mEpoch 6/18\u001b[0m\n",
      "\u001b[34m74/74 - 54s - loss: 0.2808 - accuracy: 0.9628 - val_loss: 0.2568 - val_accuracy: 0.9780 - 54s/epoch - 735ms/step\u001b[0m\n",
      "\u001b[34mEpoch 7/18\u001b[0m\n",
      "\u001b[34m74/74 - 53s - loss: 0.2731 - accuracy: 0.9709 - val_loss: 0.2385 - val_accuracy: 0.9882 - 53s/epoch - 716ms/step\u001b[0m\n",
      "\u001b[34mEpoch 8/18\u001b[0m\n",
      "\u001b[34m74/74 - 54s - loss: 0.2729 - accuracy: 0.9662 - val_loss: 0.2450 - val_accuracy: 0.9848 - 54s/epoch - 726ms/step\u001b[0m\n",
      "\u001b[34mEpoch 9/18\u001b[0m\n",
      "\u001b[34m74/74 - 55s - loss: 0.2718 - accuracy: 0.9671 - val_loss: 0.2414 - val_accuracy: 0.9882 - 55s/epoch - 750ms/step\u001b[0m\n",
      "\u001b[34mEpoch 10/18\u001b[0m\n",
      "\u001b[34m74/74 - 49s - loss: 0.2587 - accuracy: 0.9789 - val_loss: 0.2321 - val_accuracy: 0.9898 - 49s/epoch - 664ms/step\u001b[0m\n",
      "\u001b[34mEpoch 11/18\u001b[0m\n",
      "\u001b[34m74/74 - 49s - loss: 0.2603 - accuracy: 0.9789 - val_loss: 0.2369 - val_accuracy: 0.9898 - 49s/epoch - 663ms/step\u001b[0m\n",
      "\u001b[34mEpoch 12/18\u001b[0m\n",
      "\u001b[34m74/74 - 52s - loss: 0.2673 - accuracy: 0.9742 - val_loss: 0.2557 - val_accuracy: 0.9797 - 52s/epoch - 702ms/step\u001b[0m\n",
      "\u001b[34mEpoch 13/18\u001b[0m\n",
      "\u001b[34m74/74 - 54s - loss: 0.2635 - accuracy: 0.9738 - val_loss: 0.2360 - val_accuracy: 0.9898 - 54s/epoch - 731ms/step\u001b[0m\n",
      "\u001b[34mEpoch 14/18\u001b[0m\n",
      "\u001b[34m74/74 - 55s - loss: 0.2612 - accuracy: 0.9764 - val_loss: 0.2358 - val_accuracy: 0.9865 - 55s/epoch - 738ms/step\u001b[0m\n",
      "\u001b[34mEpoch 15/18\u001b[0m\n",
      "\u001b[34m74/74 - 55s - loss: 0.2595 - accuracy: 0.9738 - val_loss: 0.2323 - val_accuracy: 0.9915 - 55s/epoch - 746ms/step\u001b[0m\n",
      "\u001b[34mEpoch 16/18\u001b[0m\n",
      "\u001b[34m74/74 - 54s - loss: 0.2652 - accuracy: 0.9751 - val_loss: 0.2316 - val_accuracy: 0.9865 - 54s/epoch - 734ms/step\u001b[0m\n",
      "\u001b[34mEpoch 17/18\u001b[0m\n",
      "\u001b[34m74/74 - 54s - loss: 0.2650 - accuracy: 0.9709 - val_loss: 0.2345 - val_accuracy: 0.9932 - 54s/epoch - 733ms/step\u001b[0m\n",
      "\u001b[34mEpoch 18/18\u001b[0m\n",
      "\u001b[34m74/74 - 54s - loss: 0.2564 - accuracy: 0.9747 - val_loss: 0.2382 - val_accuracy: 0.9848 - 54s/epoch - 732ms/step\u001b[0m\n",
      "\u001b[34mSetting weights to model with maximum val_accuracy at epoch 17/18:\u001b[0m\n",
      "\u001b[34m- loss: 0.2650401294231415\u001b[0m\n",
      "\u001b[34m- accuracy: 0.9708614945411682\u001b[0m\n",
      "\u001b[34m- val_loss: 0.23450396955013275\u001b[0m\n",
      "\u001b[34m- val_accuracy: 0.9932318329811096\u001b[0m\n",
      "\u001b[34mTraining summary:\u001b[0m\n",
      "\u001b[34m- Total training duration: 972.805626355 seconds\u001b[0m\n",
      "\u001b[34m- Average training duration per epoch: 54.04475701972222 seconds\u001b[0m\n",
      "\u001b[34mEvaluating trained model on test dataset:\u001b[0m\n",
      "\u001b[34m3/3 - 1s - loss: 0.2736 - accuracy: 0.9625 - 989ms/epoch - 330ms/step\u001b[0m\n",
      "\u001b[34m- Test loss: 0.27355116605758667\u001b[0m\n",
      "\u001b[34m- Test accuracy: 0.9624999761581421\u001b[0m\n",
      "\u001b[34m- Test evaluation latency: 0.9917665430000397 seconds\u001b[0m\n",
      "\u001b[34m- Average test latency per sample: 0.3305888476666799 seconds\u001b[0m\n",
      "\u001b[34m- Average test throughput: 3.02490542877678 examples per second\u001b[0m\n",
      "\u001b[34mSaving the model with the highest val_accuracy for running inference or incremental training.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mFrom /usr/local/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mAssets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34m2023-02-09 16:27:55,651 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-02-09 16:27:55,651 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-02-09 16:27:55,651 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-02-09 16:28:07 Uploading - Uploading generated training model\n",
      "2023-02-09 16:28:07 Completed - Training job completed\n",
      "Training seconds: 1092\n",
      "Billable seconds: 1092\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "training_job_name = name_from_base(f\"slf-{model_id}-transfer-learning\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "ic_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=training_job_name,\n",
    ")\n",
    "\n",
    "if use_amt:\n",
    "    metric_definitions = next(\n",
    "        value for key, value in metric_definitions_per_model.items() if model_id.startswith(key)\n",
    "    )\n",
    "\n",
    "    hp_tuner = HyperparameterTuner(\n",
    "        ic_estimator,\n",
    "        metric_definitions[\"metrics\"][0][\"Name\"],\n",
    "        hyperparameter_ranges,\n",
    "        metric_definitions[\"metrics\"],\n",
    "        max_jobs=max_jobs,\n",
    "        max_parallel_jobs=max_parallel_jobs,\n",
    "        objective_type=metric_definitions[\"type\"],\n",
    "        base_tuning_job_name=training_job_name,\n",
    "    )\n",
    "\n",
    "    # Launch a SageMaker Tuning job to search for the best hyperparameters\n",
    "    hp_tuner.fit({\"training\": training_dataset_s3_path})\n",
    "else:\n",
    "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
    "    ic_estimator.fit({\"training\": training_dataset_s3_path, \"test\": test_dataset_s3_path}, logs=True)\n",
    "    #s3.Object(bucket, \"{output_bucket}/{output_prefix}/output/{training_job_name}/log.txt\").put(Body=ic_estimator.logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0e7503-7712-498d-b21e-8b70181f271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.120.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b44ce8-b287-408d-b70e-0d596f09a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client(\"s3\").download_file(s3_bucket, f\"{image_key}\", filename)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
