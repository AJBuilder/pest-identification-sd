{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8aa721-cf73-4e8c-b206-797336fb2a6d",
   "metadata": {},
   "source": [
    "# Training a Model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "477b49c6-1e8c-4802-9616-b9ad8edf8953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::447099698275:role/service-role/AmazonSageMaker-ExecutionRole-20230114T111418\n",
      "using bucket sagemaker-us-east-2-447099698275\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "\n",
    "print(\"using bucket %s\" % bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f4710af-9887-4280-9c0a-25aad3a6cc31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "\n",
    "# Here, we are retrieving the URIs to all the default Docker images, training scripts, and pretrained models\n",
    "# that are provided by Jumpstart\n",
    "# Note we are just retrieving links to these things. They will be assembled later in the Estimator, Model, or Predictor\n",
    "# Estimators are for training.\n",
    "# Models are for deployment.\n",
    "# Predictors are for inference.\n",
    "\n",
    "model_id, model_version = \"tensorflow-ic-imagenet-mobilenet-v2-100-224-classification-4\", \"*\"\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0093804c-b92a-46af-99f6-4425f37add46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our training data\n",
    "training_data_bucket = f\"lantern-rd-east2\"\n",
    "training_dataset_s3_path = f\"s3://{training_data_bucket}/\"\n",
    "\n",
    "# Output\n",
    "output_bucket = bucket\n",
    "output_prefix = \"slf-classifier-training\"\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "163ab627-073f-47e5-aee4-c07cfd751fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_only_top_layer': 'True', 'epochs': '5', 'batch_size': '32', 'optimizer': 'adam', 'learning_rate': '0.001', 'beta_1': '0.9', 'beta_2': '0.999', 'momentum': '0.9', 'epsilon': '1e-07', 'rho': '0.95', 'initial_accumulator_value': '0.1', 'reinitialize_top_layer': 'Auto', 'early_stopping': 'False', 'early_stopping_patience': '5', 'early_stopping_min_delta': '0.0', 'dropout_rate': '0.2', 'regularizers_l2': '0.0001', 'label_smoothing': '0.1', 'image_resize_interpolation': 'bilinear', 'augmentation': 'False', 'augmentation_random_flip': 'horizontal_and_vertical', 'augmentation_random_rotation': '0.2', 'augmentation_random_zoom': '0.1', 'binary_mode': 'False', 'eval_metric': 'accuracy', 'validation_split_ratio': '0.2', 'random_seed': '123'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\"epochs\"] = \"5\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a12bd457-fbdb-450a-b28b-b02c611a14c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter\n",
    "\n",
    "#######################################################\n",
    "# Use AMT for tuning and selecting the best model\n",
    "# Setting to false will use Automatic Model Tuning\n",
    "# Will use hp_tuner instead of ic_estimator\n",
    "use_amt = False\n",
    "######################################################\n",
    "\n",
    "# Define objective metric per framework, based on which the best model will be selected.\n",
    "metric_definitions_per_model = {\n",
    "    \"tensorflow\": {\n",
    "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Maximize\",\n",
    "    },\n",
    "    \"pytorch\": {\n",
    "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val Acc: ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Maximize\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
    "hyperparameter_ranges = {\n",
    "    \"adam-learning-rate\": ContinuousParameter(0.0001, 0.1, scaling_type=\"Logarithmic\")\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 6\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c09ec9c-dda5-4fae-a6b6-43df9c9de773",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-25 03:06:14 Starting - Starting the training job...\n",
      "2023-01-25 03:06:37 Starting - Preparing the instances for trainingProfilerReport-1674615974: InProgress\n",
      "......\n",
      "2023-01-25 03:07:37 Downloading - Downloading input data......\n",
      "2023-01-25 03:08:45 Training - Training image download completed. Training in progress....\u001b[34m2023-01-25 03:09:00.337456: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:00.337610: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:00.362913: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:02,390 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:02,403 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:02,607 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:02,625 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:02,643 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:02,653 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"augmentation\": \"False\",\n",
      "        \"augmentation_random_flip\": \"horizontal_and_vertical\",\n",
      "        \"augmentation_random_rotation\": \"0.2\",\n",
      "        \"augmentation_random_zoom\": \"0.1\",\n",
      "        \"batch_size\": \"32\",\n",
      "        \"beta_1\": \"0.9\",\n",
      "        \"beta_2\": \"0.999\",\n",
      "        \"binary_mode\": \"False\",\n",
      "        \"dropout_rate\": \"0.2\",\n",
      "        \"early_stopping\": \"False\",\n",
      "        \"early_stopping_min_delta\": \"0.0\",\n",
      "        \"early_stopping_patience\": \"5\",\n",
      "        \"epochs\": \"5\",\n",
      "        \"epsilon\": \"1e-07\",\n",
      "        \"eval_metric\": \"accuracy\",\n",
      "        \"image_resize_interpolation\": \"bilinear\",\n",
      "        \"initial_accumulator_value\": \"0.1\",\n",
      "        \"label_smoothing\": \"0.1\",\n",
      "        \"learning_rate\": \"0.001\",\n",
      "        \"momentum\": \"0.9\",\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"random_seed\": \"123\",\n",
      "        \"regularizers_l2\": \"0.0001\",\n",
      "        \"reinitialize_top_layer\": \"Auto\",\n",
      "        \"rho\": \"0.95\",\n",
      "        \"train_only_top_layer\": \"True\",\n",
      "        \"validation_split_ratio\": \"0.2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"slf-tensorflow-ic-imagenet-mobilenet-v2-2023-01-25-03-06-14-286\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-east-2/source-directory-tarballs/tensorflow/transfer_learning/ic/v2.0.7/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"augmentation\":\"False\",\"augmentation_random_flip\":\"horizontal_and_vertical\",\"augmentation_random_rotation\":\"0.2\",\"augmentation_random_zoom\":\"0.1\",\"batch_size\":\"32\",\"beta_1\":\"0.9\",\"beta_2\":\"0.999\",\"binary_mode\":\"False\",\"dropout_rate\":\"0.2\",\"early_stopping\":\"False\",\"early_stopping_min_delta\":\"0.0\",\"early_stopping_patience\":\"5\",\"epochs\":\"5\",\"epsilon\":\"1e-07\",\"eval_metric\":\"accuracy\",\"image_resize_interpolation\":\"bilinear\",\"initial_accumulator_value\":\"0.1\",\"label_smoothing\":\"0.1\",\"learning_rate\":\"0.001\",\"momentum\":\"0.9\",\"optimizer\":\"adam\",\"random_seed\":\"123\",\"regularizers_l2\":\"0.0001\",\"reinitialize_top_layer\":\"Auto\",\"rho\":\"0.95\",\"train_only_top_layer\":\"True\",\"validation_split_ratio\":\"0.2\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-east-2/source-directory-tarballs/tensorflow/transfer_learning/ic/v2.0.7/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"augmentation\":\"False\",\"augmentation_random_flip\":\"horizontal_and_vertical\",\"augmentation_random_rotation\":\"0.2\",\"augmentation_random_zoom\":\"0.1\",\"batch_size\":\"32\",\"beta_1\":\"0.9\",\"beta_2\":\"0.999\",\"binary_mode\":\"False\",\"dropout_rate\":\"0.2\",\"early_stopping\":\"False\",\"early_stopping_min_delta\":\"0.0\",\"early_stopping_patience\":\"5\",\"epochs\":\"5\",\"epsilon\":\"1e-07\",\"eval_metric\":\"accuracy\",\"image_resize_interpolation\":\"bilinear\",\"initial_accumulator_value\":\"0.1\",\"label_smoothing\":\"0.1\",\"learning_rate\":\"0.001\",\"momentum\":\"0.9\",\"optimizer\":\"adam\",\"random_seed\":\"123\",\"regularizers_l2\":\"0.0001\",\"reinitialize_top_layer\":\"Auto\",\"rho\":\"0.95\",\"train_only_top_layer\":\"True\",\"validation_split_ratio\":\"0.2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"slf-tensorflow-ic-imagenet-mobilenet-v2-2023-01-25-03-06-14-286\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-2/source-directory-tarballs/tensorflow/transfer_learning/ic/v2.0.7/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--augmentation\",\"False\",\"--augmentation_random_flip\",\"horizontal_and_vertical\",\"--augmentation_random_rotation\",\"0.2\",\"--augmentation_random_zoom\",\"0.1\",\"--batch_size\",\"32\",\"--beta_1\",\"0.9\",\"--beta_2\",\"0.999\",\"--binary_mode\",\"False\",\"--dropout_rate\",\"0.2\",\"--early_stopping\",\"False\",\"--early_stopping_min_delta\",\"0.0\",\"--early_stopping_patience\",\"5\",\"--epochs\",\"5\",\"--epsilon\",\"1e-07\",\"--eval_metric\",\"accuracy\",\"--image_resize_interpolation\",\"bilinear\",\"--initial_accumulator_value\",\"0.1\",\"--label_smoothing\",\"0.1\",\"--learning_rate\",\"0.001\",\"--momentum\",\"0.9\",\"--optimizer\",\"adam\",\"--random_seed\",\"123\",\"--regularizers_l2\",\"0.0001\",\"--reinitialize_top_layer\",\"Auto\",\"--rho\",\"0.95\",\"--train_only_top_layer\",\"True\",\"--validation_split_ratio\",\"0.2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENTATION=False\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENTATION_RANDOM_FLIP=horizontal_and_vertical\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENTATION_RANDOM_ROTATION=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENTATION_RANDOM_ZOOM=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_BETA_1=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_BETA_2=0.999\u001b[0m\n",
      "\u001b[34mSM_HP_BINARY_MODE=False\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING=False\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_MIN_DELTA=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_PATIENCE=5\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_EPSILON=1e-07\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_METRIC=accuracy\u001b[0m\n",
      "\u001b[34mSM_HP_IMAGE_RESIZE_INTERPOLATION=bilinear\u001b[0m\n",
      "\u001b[34mSM_HP_INITIAL_ACCUMULATOR_VALUE=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_LABEL_SMOOTHING=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=adam\u001b[0m\n",
      "\u001b[34mSM_HP_RANDOM_SEED=123\u001b[0m\n",
      "\u001b[34mSM_HP_REGULARIZERS_L2=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_REINITIALIZE_TOP_LAYER=Auto\u001b[0m\n",
      "\u001b[34mSM_HP_RHO=0.95\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_ONLY_TOP_LAYER=True\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_SPLIT_RATIO=0.2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages:/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument-3.4.2-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument_cext-0.2.4-py3.9-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.9 transfer_learning.py --augmentation False --augmentation_random_flip horizontal_and_vertical --augmentation_random_rotation 0.2 --augmentation_random_zoom 0.1 --batch_size 32 --beta_1 0.9 --beta_2 0.999 --binary_mode False --dropout_rate 0.2 --early_stopping False --early_stopping_min_delta 0.0 --early_stopping_patience 5 --epochs 5 --epsilon 1e-07 --eval_metric accuracy --image_resize_interpolation bilinear --initial_accumulator_value 0.1 --label_smoothing 0.1 --learning_rate 0.001 --momentum 0.9 --optimizer adam --random_seed 123 --regularizers_l2 0.0001 --reinitialize_top_layer Auto --rho 0.95 --train_only_top_layer True --validation_split_ratio 0.2\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:03.183078: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:03.183244: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2023-01-25 03:09:03.209146: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mRunning training scripts with arguments: Namespace(model_dir=PosixPath('/opt/ml/model'), train='/opt/ml/input/data/training', validation=None, test=None, pretrained_model='/opt/ml/input/data/model', hosts=['algo-1'], current_host='algo-1', verbose_one_line_per_epoch=2, checkpoint_save_best_only='True', seed=0, reinitialize_top_layer='Auto', train_only_top_layer='True', validation_split_ratio=0.2, early_stopping='False', early_stopping_patience=5, early_stopping_min_delta=0.0, dropout_rate=0.2, regularizers_l2=0.0001, label_smoothing=0.1, image_resize_interpolation='bilinear', augmentation='False', augmentation_random_flip='horizontal_and_vertical', augmentation_random_rotation=0.2, augmentation_random_zoom=0.1, epochs=5, batch_size=32, optimizer='adam', learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, momentum=0.9, rho=0.95, initial_accumulator_value=0.1, binary_mode='False', eval_metric='accuracy', random_seed=123)\u001b[0m\n",
      "\u001b[34mIgnoring unrecognized arguments: ['--validation_split_ratio', '0.2']\u001b[0m\n",
      "\u001b[34mimage size for this model is: [224, 224]\u001b[0m\n",
      "\u001b[34mCreating datasets using categorical mode for label encodings.\u001b[0m\n",
      "\u001b[34mImages for this model will be resized to image size: [224, 224]\u001b[0m\n",
      "\u001b[34mFound 4151 files belonging to 2 classes.\u001b[0m\n",
      "\u001b[34mNo Test channel provided. Performance evaluations on test dataset will be skipped.\u001b[0m\n",
      "\u001b[34mClass index to class name mapping: {0: 'not-slf', 1: 'slf'}\u001b[0m\n",
      "\u001b[34mCardinality of train dataset: 3321\u001b[0m\n",
      "\u001b[34mNumber of class examples in train dataset: {'not-slf': 2253, 'slf': 1068}\u001b[0m\n",
      "\u001b[34mCardinality of validation dataset: 830\u001b[0m\n",
      "\u001b[34mNumber of class examples in validation dataset: {'not-slf': 564, 'slf': 266}\u001b[0m\n",
      "\u001b[34mLoading the original pre-trained feature extraction model, and attaching a randomly initialized classification layer to classify input images to one of the 2 classes.\u001b[0m\n",
      "\u001b[34mSetting model to train only top layer.\u001b[0m\n",
      "\u001b[34mModel: \"model\"\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #\u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34minput_1 (InputLayer)        [(None, 224, 224, 3)]     0\u001b[0m\n",
      "\u001b[34mfeatures (KerasLayer)       (None, 1280)              2257984\u001b[0m\n",
      "\u001b[34mdropout (Dropout)           (None, 1280)              0\u001b[0m\n",
      "\u001b[34mclassification (Dense)      (None, 2)                 2562      \n",
      "                                                                 \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 2,260,546\u001b[0m\n",
      "\u001b[34mTrainable params: 2,562\u001b[0m\n",
      "\u001b[34mNon-trainable params: 2,257,984\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mSince there are 2 <= 5 labels, the metric top_5_accuracy will not be computed.\u001b[0m\n",
      "\u001b[34mSetting the evaluation metric to val_accuracy\u001b[0m\n",
      "\u001b[34mModel information:\u001b[0m\n",
      "\u001b[34m- Number of trainable parameters: 2562\u001b[0m\n",
      "\u001b[34m- Number of non-trainable parameters: 2257984\u001b[0m\n",
      "\u001b[34m- Number of parameters: 2260546\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34m[2023-01-25 03:09:15.933 ip-10-0-110-228.us-east-2.compute.internal:30 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2023-01-25 03:09:16.166 ip-10-0-110-228.us-east-2.compute.internal:30 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-01-25 03:09:16.188 ip-10-0-110-228.us-east-2.compute.internal:30 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-01-25 03:09:16.189 ip-10-0-110-228.us-east-2.compute.internal:30 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-01-25 03:09:16.189 ip-10-0-110-228.us-east-2.compute.internal:30 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-01-25 03:09:16.189 ip-10-0-110-228.us-east-2.compute.internal:30 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-01-25 03:09:16.190 ip-10-0-110-228.us-east-2.compute.internal:30 INFO hook.py:427] Monitoring the collections: metrics, sm_metrics, losses\u001b[0m\n",
      "\u001b[34m104/104 - 56s - loss: 0.3512 - accuracy: 0.9133 - val_loss: 0.2586 - val_accuracy: 0.9759 - 56s/epoch - 536ms/step\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m104/104 - 50s - loss: 0.2742 - accuracy: 0.9711 - val_loss: 0.2423 - val_accuracy: 0.9892 - 50s/epoch - 482ms/step\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m104/104 - 56s - loss: 0.2592 - accuracy: 0.9789 - val_loss: 0.2385 - val_accuracy: 0.9940 - 56s/epoch - 538ms/step\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m104/104 - 51s - loss: 0.2493 - accuracy: 0.9886 - val_loss: 0.2317 - val_accuracy: 0.9952 - 51s/epoch - 492ms/step\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m104/104 - 51s - loss: 0.2465 - accuracy: 0.9898 - val_loss: 0.2291 - val_accuracy: 0.9964 - 51s/epoch - 489ms/step\u001b[0m\n",
      "\u001b[34mSetting weights to model with maximum val_accuracy at epoch 5/5:\u001b[0m\n",
      "\u001b[34m- loss: 0.24651338160037994\u001b[0m\n",
      "\u001b[34m- accuracy: 0.9897621273994446\u001b[0m\n",
      "\u001b[34m- val_loss: 0.2290833592414856\u001b[0m\n",
      "\u001b[34m- val_accuracy: 0.9963855147361755\u001b[0m\n",
      "\u001b[34mTraining summary:\u001b[0m\n",
      "\u001b[34m- Total training duration: 264.03919359300005 seconds\u001b[0m\n",
      "\u001b[34m- Average training duration per epoch: 52.80783871860001 seconds\u001b[0m\n",
      "\u001b[34mNo test dataset available. Provide test dataset to compute test performance metrics.\u001b[0m\n",
      "\u001b[34mSaving the model with the highest val_accuracy for running inference or incremental training.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mFrom /usr/local/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mAssets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34m2023-01-25 03:13:46,261 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-01-25 03:13:46,262 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-01-25 03:13:46,262 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-01-25 03:14:46 Uploading - Uploading generated training model\n",
      "2023-01-25 03:15:19 Completed - Training job completed\n",
      "ProfilerReport-1674615974: NoIssuesFound\n",
      "Training seconds: 448\n",
      "Billable seconds: 448\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "training_job_name = name_from_base(f\"slf-{model_id}-transfer-learning\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "ic_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=training_job_name,\n",
    ")\n",
    "\n",
    "if use_amt:\n",
    "    metric_definitions = next(\n",
    "        value for key, value in metric_definitions_per_model.items() if model_id.startswith(key)\n",
    "    )\n",
    "\n",
    "    hp_tuner = HyperparameterTuner(\n",
    "        ic_estimator,\n",
    "        metric_definitions[\"metrics\"][0][\"Name\"],\n",
    "        hyperparameter_ranges,\n",
    "        metric_definitions[\"metrics\"],\n",
    "        max_jobs=max_jobs,\n",
    "        max_parallel_jobs=max_parallel_jobs,\n",
    "        objective_type=metric_definitions[\"type\"],\n",
    "        base_tuning_job_name=training_job_name,\n",
    "    )\n",
    "\n",
    "    # Launch a SageMaker Tuning job to search for the best hyperparameters\n",
    "    hp_tuner.fit({\"training\": training_dataset_s3_path})\n",
    "else:\n",
    "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
    "    ic_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)\n",
    "    #s3.Object(bucket, \"{output_bucket}/{output_prefix}/output/{training_job_name}/log.txt\").put(Body=ic_estimator.logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0e7503-7712-498d-b21e-8b70181f271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.120.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b44ce8-b287-408d-b70e-0d596f09a47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
